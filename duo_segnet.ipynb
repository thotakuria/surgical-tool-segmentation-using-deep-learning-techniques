{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrTYaSROqWWkWLBzYvrD7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thotakuria/surgical-tool-segmentation-using-deep-learning-techniques/blob/main/duo_segnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "data_transforms = transforms.Compose([\n",
        "                    transforms.CenterCrop(224),\n",
        "                    transforms.ToTensor()])\n",
        "image_datasets = datasets.ImageFolder(root= \"/content/gdrive/MyDrive/dataset\", transform=data_transforms)\n",
        "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "SBbOqT36B0te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "\n",
        "class ObjDataset(data.Dataset):\n",
        "    def __init__(self, images, gts, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "\n",
        "        return image, gt\n",
        "\n",
        "    def filter_files(self):\n",
        "        assert len(self.images) == len(self.gts)\n",
        "        images = []\n",
        "        gts = []\n",
        "        for img_path, gt_path in zip(self.images, self.gts):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            if img.size == gt.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            # return img.convert('1')\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt):\n",
        "        assert img.size == gt.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "class ValObjDataset(data.Dataset):\n",
        "    def __init__(self, images, gts, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "\n",
        "        return image, gt\n",
        "\n",
        "    def filter_files(self):\n",
        "        assert len(self.images) == len(self.gts)\n",
        "        images = []\n",
        "        gts = []\n",
        "        for img_path, gt_path in zip(self.images, self.gts):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            if img.size == gt.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            # return img.convert('1')\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt):\n",
        "        assert img.size == gt.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "def image_loader(image_root, gt_root, batch_size, image_size, split=0.8, labeled_ratio=0.05):\n",
        "    images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    train_images = images[0:int(len(images) * split)]\n",
        "    val_images = images[int(len(images) * split):]\n",
        "    train_gts = gts[0:int(len(images) * split)]\n",
        "    val_gts = gts[int(len(images) * split):]\n",
        "\n",
        "    labeled_train_images = train_images[0:int(len(train_images) * labeled_ratio)]\n",
        "    labeled_train_images_1 = labeled_train_images[0:int(len(labeled_train_images) * 0.5)]\n",
        "    labeled_train_images_2 = labeled_train_images[int(len(labeled_train_images) * 0.5):]\n",
        "    unlabeled_train_images = train_images[int(len(train_images) * labeled_ratio):]\n",
        "    labeled_train_gts = train_gts[0:int(len(train_gts) * labeled_ratio)]\n",
        "    labeled_train_gts_1 = labeled_train_gts[0:int(len(labeled_train_gts) * 0.5)]\n",
        "    labeled_train_gts_2 = labeled_train_gts[int(len(labeled_train_gts) * 0.5):]\n",
        "    unlabeled_train_gts = train_gts[int(len(train_gts) * labeled_ratio):]\n",
        "\n",
        "    labeled_train_dataset_1 = ObjDataset(labeled_train_images_1, labeled_train_gts_1, image_size)\n",
        "    labeled_train_dataset_2 = ObjDataset(labeled_train_images_2, labeled_train_gts_2, image_size)\n",
        "    unlabeled_train_dataset = ObjDataset(unlabeled_train_images, unlabeled_train_gts, image_size)\n",
        "    val_dataset = ValObjDataset(val_images, val_gts, image_size)\n",
        "\n",
        "    labeled_data_loader_1 = data.DataLoader(dataset=labeled_train_dataset_1,\n",
        "                                  batch_size=batch_size,\n",
        "                                  num_workers=1,\n",
        "                                  pin_memory=True,\n",
        "                                  shuffle=True)\n",
        "\n",
        "    labeled_data_loader_2 = data.DataLoader(dataset=labeled_train_dataset_2,\n",
        "                                            batch_size=batch_size,\n",
        "                                            num_workers=1,\n",
        "                                            pin_memory=True,\n",
        "                                            shuffle=True)\n",
        "\n",
        "    unlabeled_data_loader = data.DataLoader(dataset=unlabeled_train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          num_workers=1,\n",
        "                                          pin_memory=True,\n",
        "                                          shuffle=True)\n",
        "\n",
        "    val_loader = data.DataLoader(dataset=val_dataset,\n",
        "                                 batch_size=batch_size,\n",
        "                                 num_workers=1,\n",
        "                                 pin_memory=True,\n",
        "                                 shuffle=False)\n",
        "\n",
        "    return labeled_data_loader_1, labeled_data_loader_2, unlabeled_data_loader, val_loader"
      ],
      "metadata": {
        "id": "x_wdEYILbBQf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "CE = torch.nn.BCELoss()\n",
        "pred_label = 0\n",
        "gt_label = 1\n",
        "\n",
        "\n",
        "def make_Dis_label(label, gts):\n",
        "    D_label = np.ones(gts.shape) * label\n",
        "    D_label = Variable(torch.FloatTensor(D_label)).cuda()\n",
        "\n",
        "    return D_label\n",
        "\n",
        "\n",
        "def calc_loss(pred, target, bce_weight=0.5):\n",
        "    bce = CE(pred, target)\n",
        "    dl = 1 - dice_coef(pred, target)\n",
        "    loss = bce * bce_weight + dl * bce_weight\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def loss_sup(logit_S1, logit_S2, labels_S1, labels_S2):\n",
        "    loss1 = calc_loss(logit_S1, labels_S1)\n",
        "    loss2 = calc_loss(logit_S2, labels_S2)\n",
        "\n",
        "    return loss1 + loss2\n",
        "\n",
        "\n",
        "def loss_diff(u_prediction_1, u_prediction_2, batch_size):\n",
        "    a = CE(u_prediction_1, Variable(u_prediction_2, requires_grad=False))\n",
        "    a = a.item()\n",
        "\n",
        "    b = CE(u_prediction_2, Variable(u_prediction_1, requires_grad=False))\n",
        "    b = b.item()\n",
        "\n",
        "    loss_diff_avg = (a + b)\n",
        "    return loss_diff_avg / batch_size\n",
        "\n",
        "\n",
        "def loss_adversarial_1(D_fake_1, D_fake_2, labels_S1, labels_S2):\n",
        "    D_loss_fake_0_1 = CE(D_fake_1, make_Dis_label(pred_label, labels_S1))\n",
        "    D_loss_fake_0_2 = CE(D_fake_2, make_Dis_label(pred_label, labels_S2))\n",
        "\n",
        "    loss = D_loss_fake_0_1 + D_loss_fake_0_2\n",
        "    return loss\n",
        "\n",
        "\n",
        "def loss_adversarial_2(D_fake_1, D_real_1, D_fake_2, D_real_2, labels_S1, labels_S2):\n",
        "    D_loss_fake_0_1 = CE(D_fake_1, make_Dis_label(pred_label, labels_S1))\n",
        "    D_loss_fake_0_2 = CE(D_fake_2, make_Dis_label(pred_label, labels_S2))\n",
        "\n",
        "    D_loss_real_1 = CE(D_real_1, make_Dis_label(gt_label, labels_S1))\n",
        "    D_loss_real_2 = CE(D_real_2, make_Dis_label(gt_label, labels_S2))\n",
        "\n",
        "    loss = D_loss_fake_0_1 + D_loss_fake_0_2 + D_loss_real_1 + D_loss_real_2\n",
        "    return loss"
      ],
      "metadata": {
        "id": "rHxaBX5kbI1V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(output, target):\n",
        "    smooth = 1e-5\n",
        "\n",
        "    output = output.view(-1).data.cpu().numpy()\n",
        "    target = target.view(-1).data.cpu().numpy()\n",
        "    intersection = (output * target).sum()\n",
        "\n",
        "    return (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n"
      ],
      "metadata": {
        "id": "2eiJLEZBbPDE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score, mean_absolute_error\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batchsize', type=int, default=1, help='training batch size')\n",
        "parser.add_argument('--trainsize', type=int, default=256, help='training dataset size')\n",
        "parser.add_argument('--dataset', type=str, default='nuclei', help='dataset name')\n",
        "parser.add_argument('--threshold', type=float, default=0.5, help='threshold')\n",
        "opt = parser.parse_args()\n",
        "\n",
        "\n",
        "class Test(object):\n",
        "    def __init__(self):\n",
        "        self._init_configure()\n",
        "        self._init_logger()\n",
        "        self.model_1 = Unet()\n",
        "        self.model_2 = Unet()\n",
        "\n",
        "    def _init_configure(self):\n",
        "        with open('configs/config.yml') as fp:\n",
        "            self.cfg = yaml.safe_load(fp)\n",
        "\n",
        "    def _init_logger(self):\n",
        "\n",
        "        log_dir = 'logs/' + opt.dataset + '/test'\n",
        "\n",
        "        self.logger = get_logger(log_dir)\n",
        "        print('RUNDIR: {}'.format(log_dir))\n",
        "\n",
        "        self.save_path = log_dir\n",
        "        self.image_save_path_1 = log_dir + \"/saved_images_1\"\n",
        "        create_dir(self.image_save_path_1)\n",
        "        self.image_save_path_2 = log_dir + \"/saved_images_2\"\n",
        "        create_dir(self.image_save_path_2)\n",
        "\n",
        "        self.model_1_load_path = 'logs/' + opt.dataset + '/train/Model_1.pth'\n",
        "        self.model_2_load_path = 'logs/' + opt.dataset + '/train/Model_2.pth'\n",
        "\n",
        "    def visualize_val_input(self, var_map, i):\n",
        "        count = i\n",
        "        im = transforms.ToPILImage()(var_map.squeeze_(0).detach().cpu()).convert(\"RGB\")\n",
        "        name = '{:02d}_input.png'.format(count)\n",
        "        imageio.imwrite(self.image_save_path_1 + \"/val_\" + name, im)\n",
        "\n",
        "    def visualize_gt(self, var_map, i):\n",
        "        count = i\n",
        "        for kk in range(var_map.shape[0]):\n",
        "            pred_edge_kk = var_map[kk, :, :, :]\n",
        "            pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()\n",
        "            pred_edge_kk *= 255.0\n",
        "            pred_edge_kk = pred_edge_kk.astype(np.uint8)\n",
        "            name = '{:02d}_gt.png'.format(count)\n",
        "            imageio.imwrite(self.image_save_path_1 + \"/val_\" + name, pred_edge_kk)\n",
        "            imageio.imwrite(self.image_save_path_2 + \"/val_\" + name, pred_edge_kk)\n",
        "\n",
        "    def visualize_prediction1(self, var_map, i):\n",
        "        count = i\n",
        "        for kk in range(var_map.shape[0]):\n",
        "            pred_edge_kk = var_map[kk, :, :, :]\n",
        "            pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()\n",
        "            pred_edge_kk *= 255.0\n",
        "            pred_edge_kk = pred_edge_kk.astype(np.uint8)\n",
        "            name = '{:02d}_pred_1.png'.format(count)\n",
        "            imageio.imwrite(self.image_save_path_1 + \"/val_\" + name, pred_edge_kk)\n",
        "\n",
        "    def visualize_prediction2(self, var_map, i):\n",
        "        count = i\n",
        "        for kk in range(var_map.shape[0]):\n",
        "            pred_edge_kk = var_map[kk, :, :, :]\n",
        "            pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()\n",
        "            pred_edge_kk *= 255.0\n",
        "            pred_edge_kk = pred_edge_kk.astype(np.uint8)\n",
        "            name = '{:02d}_pred_2.png'.format(count)\n",
        "            imageio.imwrite(self.image_save_path_2 + \"/val_\" + name, pred_edge_kk)\n",
        "\n",
        "    def visualize_uncertainity(self, var_map, i):\n",
        "        count = i\n",
        "        for kk in range(var_map.shape[0]):\n",
        "            pred_edge_kk = var_map[kk, :, :, :]\n",
        "            pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()\n",
        "            pred_edge_kk *= 255.0\n",
        "            pred_edge_kk = pred_edge_kk.astype(np.uint8)\n",
        "            name = '{:02d}_pred.png'.format(count)\n",
        "            imageio.imwrite(self.image_save_path_1 + \"/uncertainity_\" + name, pred_edge_kk)\n",
        "\n",
        "    def evaluate_model_1(self, image_dir):\n",
        "\n",
        "        target_list = np.array([])\n",
        "        output_list = np.array([])\n",
        "        output_pred_list = np.array([])\n",
        "        test_dir = image_dir\n",
        "        self.logger.info(test_dir)\n",
        "\n",
        "        pred_files = glob.glob(test_dir + 'val_*_pred_1.png')\n",
        "        gt_files = glob.glob(test_dir + 'val_*_gt.png')\n",
        "\n",
        "        for file in pred_files:\n",
        "            image = Image.open(file)\n",
        "            output = np.asarray(image)\n",
        "            output = output.flatten() / 255\n",
        "            output_pred = (output > opt.threshold)\n",
        "            output_list = np.concatenate((output_list, output), axis=None)\n",
        "            output_pred_list = np.concatenate((output_pred_list, output_pred), axis=None)\n",
        "\n",
        "        for file in gt_files:\n",
        "            image = Image.open(file)\n",
        "            target = np.asarray(image)\n",
        "            target = target.flatten() / 255\n",
        "            target = (target > opt.threshold)\n",
        "            target_list = np.concatenate((target_list, target), axis=None)\n",
        "        F1_score = f1_score(target_list, output_pred_list)\n",
        "        self.logger.info(\"Model 1 F1 score : {} \".format(F1_score))\n",
        "        mae = mean_absolute_error(target_list, output_pred_list)\n",
        "        self.logger.info(\"Model 1 MAE : {} \".format(mae))\n",
        "\n",
        "    def evaluate_model_2(self, image_dir):\n",
        "\n",
        "        target_list = np.array([])\n",
        "        output_list = np.array([])\n",
        "        output_pred_list = np.array([])\n",
        "        test_dir = image_dir\n",
        "        self.logger.info(test_dir)\n",
        "\n",
        "        pred_files = glob.glob(test_dir + 'val_*_pred_2.png')\n",
        "        gt_files = glob.glob(test_dir + 'val_*_gt.png')\n",
        "\n",
        "        for file in pred_files:\n",
        "            image = Image.open(file)\n",
        "            output = np.asarray(image)\n",
        "            output = output.flatten() / 255\n",
        "            output_pred = (output > opt.threshold)\n",
        "            output_list = np.concatenate((output_list, output), axis=None)\n",
        "            output_pred_list = np.concatenate((output_pred_list, output_pred), axis=None)\n",
        "\n",
        "        for file in gt_files:\n",
        "            image = Image.open(file)\n",
        "            target = np.asarray(image)\n",
        "            target = target.flatten() / 255\n",
        "            target = (target > opt.threshold)\n",
        "            target_list = np.concatenate((target_list, target), axis=None)\n",
        "        F1_score = f1_score(target_list, output_pred_list)\n",
        "        self.logger.info(\"Model 2 F1 score : {} \".format(F1_score))\n",
        "        mae = mean_absolute_error(target_list, output_pred_list)\n",
        "        self.logger.info(\"Model 2 MAE : {} \".format(mae))\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        self.model_1.load_state_dict(torch.load(self.model_1_load_path))\n",
        "        self.model_1.cuda()\n",
        "\n",
        "        self.model_2.load_state_dict(torch.load(self.model_2_load_path))\n",
        "        self.model_2.cuda()\n",
        "\n",
        "        image_root = self.cfg[opt.dataset]['image_dir']\n",
        "        gt_root = self.cfg[opt.dataset]['mask_dir']\n",
        "\n",
        "        _, _, _, val_loader = image_loader(image_root, gt_root, opt.batchsize, opt.trainsize)\n",
        "\n",
        "        for i, pack in enumerate(val_loader, start=1):\n",
        "            with torch.no_grad():\n",
        "                images, gts = pack\n",
        "                images = Variable(images)\n",
        "                gts = Variable(gts)\n",
        "                images = images.cuda()\n",
        "                gts = gts.cuda()\n",
        "\n",
        "                prediction1 = self.model_1(images)\n",
        "                prediction1 = torch.sigmoid(prediction1)\n",
        "\n",
        "                prediction2 = self.model_2(images)\n",
        "                prediction2 = torch.sigmoid(prediction2)\n",
        "\n",
        "            self.visualize_val_input(images, i)\n",
        "            self.visualize_gt(gts, i)\n",
        "            self.visualize_prediction1(prediction1, i)\n",
        "            self.visualize_prediction2(prediction2, i)\n",
        "\n",
        "        self.evaluate_model_1(self.cfg[opt.dataset]['predictions_dir_1'])\n",
        "        self.evaluate_model_2(self.cfg[opt.dataset]['predictions_dir_2'])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Test_network = Test()\n",
        "    Test_network.run()"
      ],
      "metadata": {
        "id": "4u_RlJXfbcpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "\n",
        "def create_exp_dir(path, desc='Experiment dir: {}'):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    print(desc.format(path))\n",
        "\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "def get_logger(log_dir):\n",
        "    create_exp_dir(log_dir)\n",
        "    log_format = '%(asctime)s %(message)s'\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    fh = logging.FileHandler(os.path.join(log_dir, 'run.log'))\n",
        "    fh.setFormatter(logging.Formatter(log_format))\n",
        "    logger = logging.getLogger('Nas Seg')\n",
        "    logger.addHandler(fh)\n",
        "    return logger\n"
      ],
      "metadata": {
        "id": "UTKvBaI5bzQE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6dsRrkOar6r"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import yaml\n",
        "!pip install tensorboardX\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.autograd import Variable\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--epoch', type=int, default=200, help='epoch number')\n",
        "parser.add_argument('--lr_gen', type=float, default=1e-2, help='learning rate')\n",
        "parser.add_argument('--lr_dis', type=float, default=5e-5, help='learning rate')\n",
        "parser.add_argument('--batchsize', type=int, default=1, help='training batch size')\n",
        "parser.add_argument('--trainsize', type=int, default=256, help='training dataset size')\n",
        "parser.add_argument('--dataset', type=str, default='nuclei', help='dataset name')\n",
        "parser.add_argument('--split', type=float, default=0.8, help='training data ratio')\n",
        "parser.add_argument('--momentum', default=0.9, type=float)\n",
        "parser.add_argument('--decay', default=3e-5, type=float)\n",
        "parser.add_argument('--ratio', type=float, default=0.05, help='labeled data ratio')\n",
        "\n",
        "opt = parser.parse_args()\n",
        "CE = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "class Network(object):\n",
        "    def __init__(self):\n",
        "        self.patience = 0\n",
        "        self.best_dice_coeff_1 = False\n",
        "        self.best_dice_coeff_2 = False\n",
        "        self.model_1 = Unet()\n",
        "        self.model_2 = Unet()\n",
        "        self.critic = PixelDiscriminator()\n",
        "        self.best_mIoU, self.best_dice_coeff = 0, 0\n",
        "        self._init_configure()\n",
        "        self._init_logger()\n",
        "\n",
        "    def _init_configure(self):\n",
        "        with open('configs/config.yml') as fp:\n",
        "            self.cfg = yaml.safe_load(fp)\n",
        "\n",
        "    def _init_logger(self):\n",
        "\n",
        "        log_dir = 'logs/' + opt.dataset + '/train/'\n",
        "\n",
        "        self.logger = get_logger(log_dir)\n",
        "        print('RUNDIR: {}'.format(log_dir))\n",
        "\n",
        "        self.save_path = log_dir\n",
        "        self.image_save_path_1 = log_dir + \"/saved_images_1\"\n",
        "        self.image_save_path_2 = log_dir + \"/saved_images_2\"\n",
        "\n",
        "        create_dir(self.image_save_path_1)\n",
        "        create_dir(self.image_save_path_2)\n",
        "\n",
        "        self.save_tbx_log = self.save_path + '/tbx_log'\n",
        "        self.writer = SummaryWriter(self.save_tbx_log)\n",
        "\n",
        "    def run(self):\n",
        "        print('Learning Rate:'.format(opt.lr_gen,opt.lr_dis))\n",
        "\n",
        "        self.model_1.cuda()\n",
        "        self.model_2.cuda()\n",
        "\n",
        "        params = list(self.model_1.parameters()) + list(self.model_2.parameters())\n",
        "        dis_params = self.critic.parameters()\n",
        "        optimizer = torch.optim.SGD(params, lr=opt.lr_gen, momentum=opt.momentum)\n",
        "        dis_optimizer = torch.optim.RMSprop(dis_params, opt.lr_dis)\n",
        "\n",
        "        image_root = self.cfg[opt.dataset]['image_dir']\n",
        "        gt_root = self.cfg[opt.dataset]['mask_dir']\n",
        "\n",
        "        self.logger.info(\"Split Percentage : {} Labeled Data Ratio : {}\".format(opt.split, opt.ratio))\n",
        "        train_loader_1, train_loader_2, unlabeled_train_loader, val_loader = image_loader(image_root, gt_root,\n",
        "                                                                                          opt.batchsize, opt.trainsize,\n",
        "                                                                                          opt.split, opt.ratio)\n",
        "        self.logger.info(\n",
        "            \"train_loader_1 {} train_loader_2 {} unlabeled_train_loader {} val_loader {}\".format(len(train_loader_1),\n",
        "                                                                                                 len(train_loader_2),\n",
        "                                                                                                 len(\n",
        "                                                                                                     unlabeled_train_loader),\n",
        "                                                                                                 len(val_loader)))\n",
        "        print(\"Let's go!\")\n",
        "\n",
        "        for epoch in range(1, opt.epoch):\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_dice_val_1 = 0.0\n",
        "            running_dice_val_2 = 0.0\n",
        "\n",
        "            for i, data in enumerate(zip(train_loader_1, train_loader_2, unlabeled_train_loader)):\n",
        "                inputs_S1, labels_S1 = data[0][0], data[0][1]\n",
        "                inputs_S2, labels_S2 = data[1][0], data[1][1]\n",
        "                inputs_U, labels_U = data[2][0], data[2][1]\n",
        "\n",
        "                inputs_S1, labels_S1 = Variable(inputs_S1), Variable(labels_S1)\n",
        "                inputs_S1, labels_S1 = inputs_S1.cuda(), labels_S1.cuda()\n",
        "                inputs_S2, labels_S2 = Variable(inputs_S2), Variable(labels_S2)\n",
        "                inputs_S2, labels_S2 = inputs_S2.cuda(), labels_S2.cuda()\n",
        "                inputs_U = Variable(inputs_U)\n",
        "                inputs_U = inputs_U.cuda()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                prediction_1 = self.model_1(inputs_S1)\n",
        "                prediction_1 = torch.sigmoid(prediction_1)\n",
        "\n",
        "                u_prediction_1 = self.model_1(inputs_U)\n",
        "                u_prediction_1 = torch.sigmoid(u_prediction_1)\n",
        "                prediction_2 = self.model_2(inputs_S2)\n",
        "                prediction_2 = torch.sigmoid(prediction_2)\n",
        "\n",
        "                u_prediction_2 = self.model_2(inputs_U)\n",
        "                u_prediction_2 = torch.sigmoid(u_prediction_2)\n",
        "\n",
        "                self.critic.cuda()\n",
        "\n",
        "                Loss_sup = loss_sup(prediction_1, prediction_2, labels_S1, labels_S2)\n",
        "                Loss_diff = loss_diff(u_prediction_1, u_prediction_2, opt.batchsize)\n",
        "\n",
        "                prediction_1 = prediction_1.detach()\n",
        "                prediction_2 = prediction_2.detach()\n",
        "\n",
        "                D_fake_1 = F.interpolate(torch.sigmoid(self.critic(prediction_1)),\n",
        "                                         (prediction_1.shape[2], prediction_1.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "                D_fake_2 = F.interpolate(torch.sigmoid(self.critic(prediction_2)),\n",
        "                                         (prediction_2.shape[2], prediction_2.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "\n",
        "                D_fake3 = F.interpolate(torch.sigmoid(self.critic(u_prediction_1)),\n",
        "                                         (u_prediction_1.shape[2], u_prediction_1.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "\n",
        "                D_fake4 = F.interpolate(torch.sigmoid(self.critic(u_prediction_2)),\n",
        "                                        (u_prediction_2.shape[2], u_prediction_2.shape[3]),\n",
        "                                        mode='bilinear', align_corners=False)\n",
        "\n",
        "                ignore_mask_remain_1 = np.zeros(D_fake3.shape).astype(np.bool)\n",
        "                ignore_mask_remain_2 = np.zeros(D_fake4.shape).astype(np.bool)\n",
        "\n",
        "                Loss_adv_labeled = loss_adversarial_1(D_fake_1, D_fake_2, labels_S1, labels_S2)\n",
        "                Loss_adv_unlabeled = CE(D_fake3, make_Dis_label(gt_label, ignore_mask_remain_1)) + CE(D_fake4, make_Dis_label(gt_label, ignore_mask_remain_2))\n",
        "                Loss_adv1 = Loss_adv_labeled + Loss_adv_unlabeled\n",
        "                seg_loss = Loss_sup + 0.4 * Loss_diff + 0.2 * Loss_adv1\n",
        "\n",
        "                seg_loss.backward()\n",
        "                running_loss += seg_loss.item()\n",
        "                optimizer.step()\n",
        "                dis_optimizer.zero_grad()\n",
        "                prediction_1 = prediction_1.detach()\n",
        "                prediction_2 = prediction_2.detach()\n",
        "\n",
        "                D_fake_1 = F.interpolate(torch.sigmoid(self.critic(prediction_1)),\n",
        "                                         (prediction_1.shape[2], prediction_1.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "                D_fake_2 = F.interpolate(torch.sigmoid(self.critic(prediction_2)),\n",
        "                                         (prediction_2.shape[2], prediction_2.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "                D_real_1 = F.interpolate(torch.sigmoid(self.critic(labels_S1)),\n",
        "                                         (labels_S1.shape[2], labels_S1.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "                D_real_2 = F.interpolate(torch.sigmoid(self.critic(labels_S2)),\n",
        "                                         (labels_S2.shape[2], labels_S2.shape[3]),\n",
        "                                         mode='bilinear', align_corners=False)\n",
        "\n",
        "                Loss_adv2 = loss_adversarial_2(D_fake_1, D_real_1, D_fake_2, D_real_2, labels_S1, labels_S2)\n",
        "                Loss_adv2.backward()\n",
        "                dis_optimizer.step()\n",
        "\n",
        "            epoch_loss = running_loss / (len(train_loader_1) + len(train_loader_2))\n",
        "            self.logger.info('{} Epoch [{:03d}/{:03d}], total_loss : {:.4f}'.\n",
        "                             format(datetime.now(), epoch, opt.epoch, epoch_loss))\n",
        "\n",
        "            self.logger.info('Train loss: {}'.format(epoch_loss))\n",
        "            self.writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
        "\n",
        "            for i, pack in enumerate(val_loader, start=1):\n",
        "                with torch.no_grad():\n",
        "                    images, gts = pack\n",
        "                    images = Variable(images)\n",
        "                    gts = Variable(gts)\n",
        "                    images = images.cuda()\n",
        "                    gts = gts.cuda()\n",
        "\n",
        "                    prediction_1 = self.model_1(images)\n",
        "                    prediction_1 = torch.sigmoid(prediction_1)\n",
        "\n",
        "                    prediction_2 = self.model_2(images)\n",
        "                    prediction_2 = torch.sigmoid(prediction_2)\n",
        "\n",
        "                dice_coe_1 = dice_coef(prediction_1, gts)\n",
        "                running_dice_val_1 += dice_coe_1\n",
        "                dice_coe_2 = dice_coef(prediction_2, gts)\n",
        "                running_dice_val_2 += dice_coe_2\n",
        "\n",
        "            epoch_dice_val_1 = running_dice_val_1 / len(val_loader)\n",
        "\n",
        "            self.logger.info('Validation dice coeff model 1: {}'.format(epoch_dice_val_1))\n",
        "            self.writer.add_scalar('Validation_1/DSC', epoch_dice_val_1, epoch)\n",
        "\n",
        "            epoch_dice_val_2 = running_dice_val_2 / len(val_loader)\n",
        "\n",
        "            self.logger.info('Validation dice coeff model 1: {}'.format(epoch_dice_val_2))\n",
        "            self.writer.add_scalar('Validation_1/DSC', epoch_dice_val_2, epoch)\n",
        "\n",
        "            mdice_coeff_1 = epoch_dice_val_1\n",
        "            mdice_coeff_2 = epoch_dice_val_2\n",
        "\n",
        "            if self.best_dice_coeff_1 < mdice_coeff_1:\n",
        "                self.best_dice_coeff_1 = mdice_coeff_1\n",
        "                self.save_best_model_1 = True\n",
        "\n",
        "                if not os.path.exists(self.image_save_path_1):\n",
        "                    os.makedirs(self.image_save_path_1)\n",
        "\n",
        "                copy_tree(self.image_save_path_1, self.save_path + '/best_model_predictions_1')\n",
        "                self.patience = 0\n",
        "            else:\n",
        "                self.save_best_model_1 = False\n",
        "                self.patience += 1\n",
        "\n",
        "            if self.best_dice_coeff_2 < mdice_coeff_2:\n",
        "                self.best_dice_coeff_2 = mdice_coeff_2\n",
        "                self.save_best_model_2 = True\n",
        "\n",
        "                if not os.path.exists(self.image_save_path_2):\n",
        "                    os.makedirs(self.image_save_path_2)\n",
        "\n",
        "                copy_tree(self.image_save_path_2, self.save_path + '/best_model_predictions_2')\n",
        "                self.patience = 0\n",
        "            else:\n",
        "                self.save_best_model_2 = False\n",
        "                self.patience += 1\n",
        "\n",
        "            Checkpoints_Path = self.save_path + '/Checkpoints'\n",
        "\n",
        "            if not os.path.exists(Checkpoints_Path):\n",
        "                os.makedirs(Checkpoints_Path)\n",
        "\n",
        "            if self.save_best_model_1:\n",
        "                torch.save(self.model_1.state_dict(), Checkpoints_Path + '/Model_1.pth')\n",
        "                torch.save(self.critic.state_dict(), Checkpoints_Path + '/Critic.pth')\n",
        "\n",
        "            if self.save_best_model_2:\n",
        "                torch.save(self.model_2.state_dict(), Checkpoints_Path + '/Model_2.pth')\n",
        "                torch.save(self.critic.state_dict(), Checkpoints_Path + '/Critic.pth')\n",
        "\n",
        "            self.logger.info(\n",
        "                'current best dice coef model 1 {}, model 2 {}'.format(self.best_dice_coeff_1, self.best_dice_coeff_2))\n",
        "            self.logger.info('current patience :{}'.format(self.patience))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_network = Network()\n",
        "    train_network.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_image = (gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))\n",
        "plt.imshow(norm_image)"
      ],
      "metadata": {
        "id": "fkJSuS0IygYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}